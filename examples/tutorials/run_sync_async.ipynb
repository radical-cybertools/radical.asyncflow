{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "259e3b40-18bd-4ed8-b4e4-fa69dd5c3d49",
   "metadata": {},
   "source": [
    "# Execute async/sync workflows with Radical and Dask execution backends.\n",
    "\n",
    "**The goal of this notebook is to:**\n",
    "\n",
    "1. Demonstrate that, in order to use `radical.asyncflow` within Jupyter, you must set the appropriate environment variables.  \n",
    "2. Showcase the ability to use both synchronous and asynchronous execution within Jupyter.  \n",
    "3. Highlight the support for different execution backends.  \n",
    "4. Compare the performance when submitting 5 workflows synchronously versus asynchronously.\n",
    "\n",
    "> **Note:** Asynchronous execution does not necessarily imply full parallelism. True parallelism ultimately depends on the capabilities and configuration of the execution backend you are using.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b087e155-9214-4efb-b36b-8ad45f0e1b88",
   "metadata": {},
   "source": [
    "### Sync workflows with Dask\n",
    "We will execute 5 simple workflows in sync approach (sequentially) using Dask Distributed execution backend."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "53c7b09b-92bd-44c0-adc8-d3679863748c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: FLOW_JUPYTER_ASYNC=FALSE\n",
      "Dask backend initialized with dashboard at http://127.0.0.1:8787/status\n",
      "Starting workflow 0 at 1749510548.2828848\n",
      "Successfully submitted sync task task.0001\n",
      "Successfully submitted sync task task.0000\n",
      "Successfully submitted sync task task.0002\n",
      "1749510548.8966858\n",
      "Workflow 0 completed at 1749510548.909121\n",
      "\n",
      "Starting workflow 1 at 1749510548.9091806\n",
      "Successfully submitted sync task task.0003\n",
      "Successfully submitted sync task task.0004\n",
      "Successfully submitted sync task task.0005\n",
      "1749510549.8899374\n",
      "Workflow 1 completed at 1749510549.8928144\n",
      "\n",
      "Starting workflow 2 at 1749510549.8928246\n",
      "Successfully submitted sync task task.0007\n",
      "Successfully submitted sync task task.0006\n",
      "Successfully submitted sync task task.0008\n",
      "1749510550.90357\n",
      "Workflow 2 completed at 1749510550.9149003\n",
      "\n",
      "Starting workflow 3 at 1749510550.9149365\n",
      "Successfully submitted sync task task.0009\n",
      "Successfully submitted sync task task.0010\n",
      "Successfully submitted sync task task.0011\n",
      "1749510551.9057448\n",
      "Workflow 3 completed at 1749510551.9168024\n",
      "\n",
      "Starting workflow 4 at 1749510551.916839\n",
      "Successfully submitted sync task task.0013\n",
      "Successfully submitted sync task task.0012\n",
      "Successfully submitted sync task task.0014\n",
      "1749510552.9027529\n",
      "Workflow 4 completed at 1749510552.908848\n",
      "\n",
      "Total time running synchronously is: 4.626201391220093\n",
      "Dask client shutdown complete\n"
     ]
    }
   ],
   "source": [
    "%env FLOW_JUPYTER_ASYNC=FALSE\n",
    "import time\n",
    "\n",
    "from radical.asyncflow import WorkflowEngine\n",
    "from radical.asyncflow import DaskExecutionBackend\n",
    "\n",
    "backend = DaskExecutionBackend({'n_workers': 2,\n",
    "                               'threads_per_worker': 1})\n",
    "\n",
    "flow = WorkflowEngine(backend=backend)\n",
    "\n",
    "@flow.function_task\n",
    "def task1(*args):\n",
    "    return time.time()\n",
    "\n",
    "@flow.function_task\n",
    "def task2(*args):\n",
    "    return time.time()\n",
    "\n",
    "@flow.function_task\n",
    "def task3(*args):\n",
    "    return time.time()\n",
    "\n",
    "\n",
    "\n",
    "def run_wf(wf_id):\n",
    "\n",
    "    print(f'Starting workflow {wf_id} at {time.time()}')\n",
    "    t3 = task3(task1(), task2())\n",
    "    print(t3.result())\n",
    "    print (f'Workflow {wf_id} completed at {time.time()}\\n')\n",
    "\n",
    "start_time = time.time()\n",
    "for i in range(5):\n",
    "    run_wf(i)\n",
    "end_time = time.time()\n",
    "\n",
    "print(f'Total time running synchronously is: {end_time - start_time}')\n",
    "\n",
    "flow.shutdown()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "535bfee2-5167-4fc1-83e8-b962db9b5f38",
   "metadata": {},
   "source": [
    "### Async workflows with Dask\n",
    "We will execute 5 simple workflows in an async approach (concurrently) using Dask Distributed execution backend."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6979aa18-4d03-4486-b4ad-6b59b2925b80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: FLOW_JUPYTER_ASYNC=TRUE\n",
      "Dask backend initialized with dashboard at http://127.0.0.1:8787/status\n",
      "Starting workflow 0 at 1749510556.4625962\n",
      "Starting workflow 1 at 1749510556.4627974\n",
      "Starting workflow 2 at 1749510556.4629452\n",
      "Starting workflow 3 at 1749510556.4631262\n",
      "Starting workflow 4 at 1749510556.463257\n",
      "Successfully submitted async task task.0015\n",
      "Successfully submitted async task task.0018\n",
      "Successfully submitted async task task.0027\n",
      "Successfully submitted async task task.0016\n",
      "Successfully submitted async task task.0019\n",
      "Successfully submitted async task task.0022\n",
      "Successfully submitted async task task.0021\n",
      "Successfully submitted async task task.0028\n",
      "Successfully submitted async task task.0025\n",
      "Successfully submitted async task task.0024\n",
      "Successfully submitted async task task.0026\n",
      "Successfully submitted async task task.0029\n",
      "Successfully submitted async task task.0023\n",
      "Successfully submitted async task task.0020\n",
      "Successfully submitted async task task.0017\n",
      "1749510557.0891185\n",
      "Workflow 3 completed at 1749510557.5697157\n",
      "\n",
      "1749510557.1066883\n",
      "Workflow 4 completed at 1749510557.569872\n",
      "\n",
      "1749510557.1093435\n",
      "Workflow 2 completed at 1749510557.5699859\n",
      "\n",
      "1749510557.1142259\n",
      "Workflow 1 completed at 1749510557.5700903\n",
      "\n",
      "1749510557.1159475\n",
      "Workflow 0 completed at 1749510557.5701952\n",
      "\n",
      "Total time running asynchronously is: 1.1087672710418701\n",
      "Dask client shutdown complete\n",
      "Shutdown is triggered, terminating the resources gracefully\n"
     ]
    }
   ],
   "source": [
    "%env FLOW_JUPYTER_ASYNC=TRUE\n",
    "import time\n",
    "import asyncio\n",
    "\n",
    "from radical.asyncflow import WorkflowEngine\n",
    "from radical.asyncflow import DaskExecutionBackend\n",
    "\n",
    "backend = DaskExecutionBackend({'n_workers': 2,\n",
    "                               'threads_per_worker': 1})\n",
    "\n",
    "flow = WorkflowEngine(backend=backend)\n",
    "\n",
    "@flow.function_task\n",
    "async def task1(*args):\n",
    "    return time.time()\n",
    "\n",
    "@flow.function_task\n",
    "async def task2(*args):\n",
    "    return time.time()\n",
    "\n",
    "@flow.function_task\n",
    "async def task3(*args):\n",
    "    return time.time()\n",
    "\n",
    "\n",
    "\n",
    "async def run_wf(wf_id):\n",
    "\n",
    "    print(f'Starting workflow {wf_id} at {time.time()}')\n",
    "    t3 = task3(task1(), task2())\n",
    "    print(await t3)\n",
    "    print (f'Workflow {wf_id} completed at {time.time()}\\n')\n",
    "\n",
    "start_time = time.time()\n",
    "results = await asyncio.gather(*[run_wf(i) for i in range(5)])\n",
    "end_time = time.time()\n",
    "\n",
    "print(f'Total time running asynchronously is: {end_time - start_time}')\n",
    "\n",
    "# We are in an async context so we have to use **await**\n",
    "await flow.shutdown()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e76bbe4-caef-4d2c-ac1c-debc71b8b7a2",
   "metadata": {},
   "source": [
    "### Async workflows with RadicalPilot \n",
    "We will execute 5 workflows in async approach (in prallel) using execution backend.\n",
    "Note that, you can use any other backends with the same approach like: ThreadPool, PorcessPool, or DaskParallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4e7a2598-9651-4433-9708-a8eaf15f3b68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: FLOW_JUPYTER_ASYNC=TRUE\n",
      "RadicalPilot execution backend started successfully\n",
      "\n",
      "Starting workflow 0 at 1749510566.4281347\n",
      "Starting workflow 1 at 1749510566.428254\n",
      "Starting workflow 2 at 1749510566.4283452\n",
      "Starting workflow 3 at 1749510566.4284348\n",
      "Starting workflow 4 at 1749510566.4284985\n",
      "task4 from 0 got result I got executed at\n",
      "Mon Jun  9 11:09:41 PM UTC 2025\n",
      "\n",
      "submitted task5\n",
      "task4 from 1 got result I got executed at\n",
      "Mon Jun  9 11:09:41 PM UTC 2025\n",
      "\n",
      "submitted task5\n",
      "task4 from 4 got result I got executed at\n",
      "Mon Jun  9 11:09:41 PM UTC 2025\n",
      "\n",
      "submitted task5\n",
      "task4 from 2 got result I got executed at\n",
      "Mon Jun  9 11:09:41 PM UTC 2025\n",
      "\n",
      "submitted task5\n",
      "task4 from 3 got result I got executed at\n",
      "Mon Jun  9 11:09:41 PM UTC 2025\n",
      "\n",
      "submitted task5\n",
      "Workflow 0 completed at 1749510582.55685\n",
      "\n",
      "Workflow 4 completed at 1749510582.5577853\n",
      "\n",
      "Workflow 3 completed at 1749510582.5578773\n",
      "\n",
      "Workflow 2 completed at 1749510582.5579698\n",
      "\n",
      "Workflow 1 completed at 1749510582.5580425\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%env FLOW_JUPYTER_ASYNC=TRUE\n",
    "import time\n",
    "import asyncio\n",
    "\n",
    "from radical.asyncflow import WorkflowEngine\n",
    "from radical.asyncflow import RadicalExecutionBackend\n",
    "\n",
    "\n",
    "async def main():\n",
    "    backend = RadicalExecutionBackend({'resource': 'local.localhost'})\n",
    "    flow = WorkflowEngine(backend=backend)\n",
    "    \n",
    "    @flow.executable_task\n",
    "    async def task1(*args):\n",
    "        return '/bin/echo \"I got executed at\" && /bin/date'\n",
    "    \n",
    "    @flow.executable_task\n",
    "    async def task2(*args):\n",
    "        return '/bin/echo \"I got executed at\" && /bin/date'\n",
    "    \n",
    "    @flow.executable_task\n",
    "    async def task3(*args):\n",
    "        return '/bin/echo \"I got executed at\" && /bin/date'\n",
    "    \n",
    "    @flow.executable_task\n",
    "    async def task4(*args):\n",
    "        return '/bin/echo \"I got executed at\" && /bin/date'\n",
    "    \n",
    "    @flow.executable_task\n",
    "    async def task5(*args):\n",
    "        return '/bin/echo \"I got executed at\" && /bin/date'\n",
    "    \n",
    "    async def run_wf(wf_id):\n",
    "        print(f'Starting workflow {wf_id} at {time.time()}')\n",
    "        t1 = task1()\n",
    "        t2 = task2(t1)\n",
    "        t3 = task3(t1, t2)\n",
    "        t4 = task4(t3)\n",
    "\n",
    "        res = await t4\n",
    "        if res:\n",
    "            print(f'task4 from {wf_id} got result {res}')\n",
    "            t5 = task5()\n",
    "            print('submitted task5')\n",
    "            await t5\n",
    "\n",
    "        print (f'Workflow {wf_id} completed at {time.time()}\\n')\n",
    "\n",
    "    # Run workflows concurrently\n",
    "    results = await asyncio.gather(*[run_wf(i) for i in range(5)])\n",
    "\n",
    "    # We are in an async context, so we have to use **await**\n",
    "    await flow.shutdown()\n",
    "\n",
    "await main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
